<!DOCTYPE html>
<html>

  	<head>
    	<title>Brett Baribault Bankson</title>
    	<link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">
    	<link href="https://fonts.googleapis.com/css?family=Nanum+Gothic&display=swap" rel="stylesheet">
    	<link href="https://fonts.googleapis.com/css?family=Comfortaa&display=swap" rel="stylesheet">
    	<link href="/static/pages.css" rel="stylesheet" type="text/css">
    	<script src="https://kit.fontawesome.com/8ad481cdeb.js"></script>
    	<meta name="viewport" content="width=device-width, initial-scale=1">
	</head>

	<script>
		
	</script>

	<style>

		body {
			font-family: 'Nanum Gothic', sans-serif;
			padding:0px !important;
			margin:0px !important;
		}

		#container {
			width:100%;
			overflow-x:none;
		}

		#title_div{
			padding:0px 25px 0px 25px;
			top:60px;
			font-family: 'Comfortaa', cursive;
			line-height:50px;
			font-size:50px;
			margin-bottom:20px;
		}

		.sub_header{
			color: #234E52; font-size:2rem;
		}

		.card {
			padding:25px;
			display:table;
		}

		.description{
			display:table-cell;
			width:50%;
			padding:20px;
		}

		.question{
			display:table-cell;
			vertical-align: middle;
			width:50%;
			padding:20px;
		}

		.fa-question-circle{
			padding-top:4px;
			font-size:2rem;
			color: #285E61;
		}

		/*.orange_question{
			color: #FADDD1;
		}*/

		/*.teal_question{
			color: #285E61;
		}*/

		.emphasis-span{
			font-family: 'Nanum Gothic Extra-Bold', sans-serif;
		}

		.question-span{
			display:table;
		}

		.question-cell{
			display:table-cell;
			vertical-align: top;
			padding-bottom:15px;
		}

		.description-header{
			text-transform: uppercase;
			font-size: 1.2rem; 
			font-family: 'Nanum Gothic Extra-Bold', sans-serif;
			color: #285E61;
		}

		@media screen and (max-width: 480px) {
			#title_div{
				text-align:center;
			}
			.card {
			    display: block !important;
			    padding:20px 10px 0px 10px;
			}
			.description, .question {
			  	padding-top:0px !important;
			    display: inline-block !important;
			    width:auto !important;
			}

			.sub_header {
			  	font-size:1.5rem;
			}

			.white_background{
				background-color: white !important;
			}

			.white_background: .fa-question-circle{
				color: #FADDD1 !important;
			}
		}

	</style>
	
	<body>
		<div class="nav">
			<a href="/" style="margin-right:30px">Home</a>
			<a href="/about" style="margin-right:30px">About</a>
			<a href="/research" style="margin-right:30px">Research</a>
			<a href="/food">Food</a>
		</div>

		<div id="container">
			<div class="white_background" id="title_div">
				RESEARCH
			</div>

			<div class="white_background" style="padding:0px 25px 25px 25px">
				<span class="sub_header">The human brain rapidly and effortlessly extracts visual information from our environments on a millisecond-to-millisecond basis.</span>

				<p>
					How does coordinated activity throughout visually responsive areas of the brain <span class="emphasis-span">compute this input to yield high-level information</span> that informs mental states and behavior? There are several research avenues I’m working on to further our understanding of this process, using spatiotemporally-resolved recordings from <i>intracranial electroencephalography (iEEG)</i> to provide sensitive and dynamic portraits of brain activity.
				</p>
			</div>

			<div class="card">
				<div class="description">
					<span class="description-header">
						Spatiotemporal dynamics of face perception and natural vision
					</span>
					<br>
					When we see a face, we encode information from many feature dimensions – identity, age, gender, expression, gaze direction, etc. These features are functionally relevant and shape our interpretation of people in front of us. 
				</div>
				<div class="question">
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle orange_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px;">
							How are different face feature dimensions that form and motion-related aspects encoded in time across ventral and dorsal visual streams?
						</div>
					</div>
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle orange_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px">
							Do non-face preferring areas represent face information that is independent from canonical face preferring areas, and does this extend to other categories of visual objects?
						</div>
					</div>
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle orange_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px">
							How does the brain extract identity and affective information from dynamic videos of spontaneous facial expressions?
						</div>
					</div>
				</div>
			</div>

			<div class="card white_background">
				<div class="description">
					<span class="description-header">
						Retinotopy and visual perception
					</span>
					<br>
					The location of an object in visual space drives neural activity selectively according to position near or far from fixation and along the horizontal and vertical meridians. The time course by which activity in category-selective areas is modulated by retinotopic variation is not well understood, and I’m working to better quantify the relationship between retinotopy and high-level visual processing.
				</div>
				<div class="question">
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle teal_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px">
							How does the position of a face in the left or right visual hemifield affect the representation of face identity in ventral temporal face selective areas?
						</div>
					</div>
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle teal_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px">
							When does variation in retinotopic location at a fixed eccentricity affect representational fidelity for individual faces, words, and phase-scrambled stimuli?
						</div>
					</div>
				</div>
			</div>

			<div class="card">
				<div class="description">
					<span class="description-header">
						Numerical cognition and visual perception
					</span>
					<br>
					Most numerical reasoning that humans engage in relies on symbolic number characters (digits) to represent nonsymbolic magnitude information. It is currently unclear the extent to which magnitude representations are shared across representational formats (digits, words, dot arrays), and furthermore how these representations emerge in time. I'm currently working on these questions with collaborators at Pitt and Harvard.
				</div>
				<div class="question">
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle orange_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px">
							What is the time course by which individual numbers across various representational formats can be classified from whole-head MEG signal, and how do models of low-level visual features and magnitude explain this evoked response?
						</div>
					</div>
					<div class="question-span">
						<div class="question-cell">
							<i class="far fa-question-circle orange_question"></i>
						</div>
						<div class="question-cell" style="padding-left: 20px">
							How do number-selective sites in VTC and the inferior parietal sulcus (IPS) interact to assign magnitude information to visually-perceived digits and dot displays?
						</div>
					</div>
				</div>
			</div>
		</div>

	</body>
</html>
